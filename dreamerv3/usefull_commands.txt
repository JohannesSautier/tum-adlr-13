# ---------------------------------------------------------------------------- #
#                                 Installations                                #
# ---------------------------------------------------------------------------- #

# ------------------------ Connnect to cloud instance: ----------------------- #
gcloud compute config-ssh


# ---------------------------- Install Miniconda: ---------------------------- #
mkdir -p ~/miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm -rf ~/miniconda3/miniconda.sh

~/miniconda3/bin/conda init bash
~/miniconda3/bin/conda init zsh

# ------------------------------ Get conda env: ------------------------------ #
conda create -n "ADLR" python=3.11
conda activate ADLR

# ------------------------ Get general installations: ------------------------ #
sudo apt-get update && apt-get install -y
sudo apt-get install ffmpeg git vim curl software-properties-common
sudo apt-get install libglew-dev x11-xserver-utils xvfb
sudo apt-get clean


# ---------------------- Get environment installations: ---------------------- #
pip install dm_control
pip install crafter


# ---------------- Get installations from the Readme and Jax: ---------------- #
pip install -U -r tum-adlr-13/dreamerv3/embodied/requirements.txt
pip install -U -r tum-adlr-13/dreamerv3/dreamerv3/requirements.txt \
  -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html

-> Incase there appears a Tensorflow waring try to install pip install ml-dtypes==0.3.1 and then the requirments.txt files again
-> Does not really work beacause then Jax is not uptodate



# ---------------------------------------------------------------------------- #
#                               Run in debug mode                              #
# ---------------------------------------------------------------------------- #

    python tum-adlr-13/dreamerv3/dreamerv3/main.py \
    --logdir ~/logir_new_model/{timestamp} \
    --configs dmc_proprio debug \
    --batch_size 1 \
    --run.steps 3000 

Evaluate this model: 
    python tum-adlr-13/dreamerv3/dreamerv3/main.py --logdir ~/logir_new_model/{timestamp} --configs dmc_proprio debug --batch_size 1 --run.steps 3000 --run.from_checkpoint ~/logir_new_model/20240619T134233/checkpoint.ckpt --run.script eval_only

Launch the tensorboard: 
    tensorboard --logdir logir_new_model/20240619T134632


# ---------------------------------------------------------------------------- #
<<<<<<< HEAD
#                       Run a walker walk training script                      #
# ---------------------------------------------------------------------------- #
Run this model: 
    python tum-adlr-13/dreamerv3/dreamerv3/main.py --logdir ~/tum-adlr-13/Logs/logdir1/{timestamp} --configs dmc_proprio --run.script train --seed 3 

Evaluate this model: 
    python tum-adlr-13/dreamerv3/dreamerv3/main.py --logdir ~/logdir/{timestamp} --configs dmc_proprio --run.script eval_only --run.from_checkpoint ~/logdir/20240628T155338/checkpoint.ckpt --run.num_envs 1 --run.num_envs_eval 1 --run.steps 3000

Evaluate this model completly: 
    python tum-adlr-13/dreamerv3/dreamerv3/main.py --logdir ~/logdir/{timestamp} --configs dmc_proprio --run.script eval_only --run.from_checkpoint ~/logdir/20240628T155338/checkpoint.ckpt 

Load the tensorboard event file: 
    tensorboard --logdir ~/logdir/20240702T201609

Run the video maker: python tum-adlr-13/dreamerv3/make_video.py
=======
#                       Things to try out from the issues                      #
# ---------------------------------------------------------------------------- #


Reproducing results: 
-If you use more than 1 env instance they need to have the same enivonrment seed to produce a similar result 
-Experimentes were run 3 seeds per task and then the mean and std were calculated
-For my walker walk change the train_ratio to get the correct result 



 Running policy locally: 
 1. Train an agent normally 
  python dreamerv3/train.py --run.logdir ~/logdir/train --configs crafter --run.script train
 2. Minimal example to load the agent by myselfe. Look into eval_only.py to see implementation 
 
>>>>>>> f6028f35995e04a672579e973a24fb27f3ef404f
